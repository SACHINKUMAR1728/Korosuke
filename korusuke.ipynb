{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q langchain langchain-community langchain-mistralai chromadb pypdf numpy regex\n",
    "# !pip install scikit-learn\n",
    "# pip install ollama\n",
    "# !pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\n",
    "import requests.exceptions as req_exc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SECURITY_RANKS = {\n",
    "    \"public\": 1,\n",
    "    \"confidential\": 2,\n",
    "    \"restricted\": 3\n",
    "}\n",
    "\n",
    "\n",
    "PROHIBITED_PATTERNS = {\n",
    "    \"public\": [r\"\\b(internal[\\s-]?ip)\\b\", r\"\\b(passw(o)?r?d)\\b\"],\n",
    "    \"confidential\": [r\"\\b(database[\\s-]?access)\\b\"],\n",
    "    \"restricted\": [r\"\\b(top[\\s-]?secret\\b)\", r\"\\b(executive[\\s-]?compensation\\b)\"]  # New patterns\n",
    "}\n",
    "\n",
    "# LM Studio configuration\n",
    "LM_STUDIO_ENDPOINT = \"http://10.1.82.21:8080\"\n",
    "EMBEDDING_MODEL = \"text-embedding-nomic-embed-text-v1.5@f32\"\n",
    "LLM_MODEL = \"gemma-3-27b-it\"\n",
    "\n",
    "# Processing parameters\n",
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 150\n",
    "RETRIEVAL_LIMIT = 20  \n",
    "FINAL_LIMIT = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sachin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pypdf\\_crypt_providers\\_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from this module in 48.0.0.\n",
      "  from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.embeddings import Embeddings\n",
    "from typing import List\n",
    "\n",
    "class LMStudioEmbedder(Embeddings):\n",
    "    @retry(\n",
    "        stop=stop_after_attempt(3),\n",
    "        wait=wait_exponential(multiplier=1, min=2, max=10),\n",
    "        retry=(\n",
    "            retry_if_exception_type(req_exc.ConnectionError) |\n",
    "            retry_if_exception_type(req_exc.Timeout) |\n",
    "            retry_if_exception_type(req_exc.HTTPError)\n",
    "    ))\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        response = requests.post(\n",
    "            f\"{LM_STUDIO_ENDPOINT}/v1/embeddings\",\n",
    "            json={\"model\": EMBEDDING_MODEL, \"input\": texts},\n",
    "            timeout=10\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        return [item[\"embedding\"] for item in response.json()[\"data\"]]\n",
    "    \n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        return self.embed_documents([text])[0]\n",
    "    \n",
    "\n",
    "\n",
    "embedder = LMStudioEmbedder()\n",
    "\n",
    "# Load and process documents\n",
    "loader = PyPDFDirectoryLoader(\"data\")\n",
    "raw_docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP\n",
    ")\n",
    "\n",
    "processed_docs = []\n",
    "for doc in text_splitter.split_documents(raw_docs):\n",
    "    file_path = Path(doc.metadata[\"source\"])\n",
    "    folder_name = file_path.parent.name.lower()\n",
    "    \n",
    "    \n",
    "    if folder_name == \"restricted\":\n",
    "        security_level = SECURITY_RANKS[\"restricted\"]\n",
    "    else:\n",
    "        security_level = SECURITY_RANKS.get(folder_name, SECURITY_RANKS[\"public\"])\n",
    "    \n",
    "    processed_docs.append({\n",
    "        \"page_content\": doc.page_content,\n",
    "        \"metadata\": {\"security_level\": security_level}\n",
    "    })\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=[Document(**doc) for doc in processed_docs],\n",
    "    embedding=embedder,\n",
    "    persist_directory=\"secure_chroma_db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_store._collection.embedding_function = embedder.embed_documents\n",
    "\n",
    "def security_check(text, level):\n",
    "    for pattern in PROHIBITED_PATTERNS.get(level, []):\n",
    "        if re.search(pattern, text, re.IGNORECASE):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def format_response(prompt, context, security_level):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": f\"Security Level: {security_level}\\nContext: {context}\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RETRIEVED CONTEXT ===\n",
      "Policy Internal Analysis - Restricted\n",
      "Access Level: Restricted\n",
      "This document contains internal analysis and implementation details of the policy.\n",
      "It includes internal discussions, risk assessments, and strategies for phased implementation.\n",
      "Only authorized personnel should access this document.\n",
      "Key Points:\n",
      "1. Implementation will occur in three phases: Pilot, Rollout, and Full Integration.\n",
      "2. Risk assessment includes financial, operational, and reputational factors.\n",
      "3. Key performance indicators (KPIs) will measure the success of the policy.\n",
      "Policy Overview - Public Information\n",
      "Access Level: Public\n",
      "This document outlines the general guidelines and objectives of the new policy. \n",
      "The policy aims to ensure transparency, efficiency, and compliance with legal standards. \n",
      "It covers the rights and responsibilities of stakeholders, operational procedures, and expected\n",
      "outcomes.\n",
      "Key Points:\n",
      "1. The policy is designed to improve operational efficiency and legal compliance.\n",
      "2. It applies to all employees and stakeholders involved in company operations.\n",
      "3. The policy will be reviewed annually to incorporate necessary changes.\n",
      "Policy Classified Details - Confidential\n",
      "Access Level: Confidential\n",
      "This document contains highly sensitive data regarding the policy. \n",
      "It includes financial projections, classified legal strategies, and confidential stakeholder agreements.\n",
      "Unauthorized access to this document is strictly prohibited.\n",
      "Key Points:\n",
      "1. Budget allocation for this policy implementation is $5 million over three years.\n",
      "2. Legal agreements with third parties are classified and stored in secured databases.\n",
      "3. The policy includes undisclosed strategic partnerships with external organizations.\n",
      "==============================\n",
      "\n",
      "Response: Pilot, Rollout, and Full Integration.\n"
     ]
    }
   ],
   "source": [
    "question = \"what are three phases of implementation of policy?\"\n",
    "user_level = \"restricted\"  # Example user level\n",
    "\n",
    "def normalize_content(text: str) -> str:\n",
    "    \"\"\"Normalize text for deduplication\"\"\"\n",
    "    # Remove all whitespace (including newlines) and lowercase\n",
    "    return re.sub(r'\\s+', ' ', text).strip().lower()\n",
    "\n",
    "\n",
    "try:\n",
    "    # Get adjusted retrieval limit\n",
    "    total_docs = vector_store._collection.count()\n",
    "    retrieval_limit = min(RETRIEVAL_LIMIT, total_docs)\n",
    "    \n",
    "    # Retrieve documents\n",
    "    docs = vector_store.similarity_search(\n",
    "        question, \n",
    "        k=retrieval_limit,\n",
    "        filter={\"security_level\": {\"$lte\": SECURITY_RANKS[user_level.lower()]}}\n",
    "    )\n",
    "    \n",
    "    # Deduplicate and filter\n",
    "    seen_hashes = set()\n",
    "    filtered_docs = []\n",
    "    for doc in docs:\n",
    "        normalized = normalize_content(doc.page_content)\n",
    "        content_hash = hash(normalized)\n",
    "    \n",
    "        if content_hash not in seen_hashes and security_check(doc.page_content, user_level):\n",
    "            seen_hashes.add(content_hash)\n",
    "            filtered_docs.append(doc)\n",
    "        if len(filtered_docs) >= FINAL_LIMIT:\n",
    "            break\n",
    "\n",
    "    # Print retrieved context\n",
    "    print(\"=== RETRIEVED CONTEXT ===\")\n",
    "    context = \"\\n\".join([doc.page_content for doc in filtered_docs])\n",
    "    print(context)\n",
    "    print(\"=\"*30 + \"\\n\")\n",
    "\n",
    "    if not filtered_docs:\n",
    "        print(\"Couldn't find context\")\n",
    "    else:\n",
    "        # Create strict system prompt\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"\"\"You are a security analyst. Answer ONLY using the context below.\n",
    "                If the answer isn't in the context, respond with \"Couldn't find context\".\n",
    "                DO NOT use any prior knowledge.\n",
    "                \n",
    "                Context:\n",
    "                {context}\"\"\"\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ]\n",
    "        \n",
    "        # Make API call\n",
    "        response = requests.post(\n",
    "            f\"{LM_STUDIO_ENDPOINT}/v1/chat/completions\",\n",
    "            json={\n",
    "                \"model\": LLM_MODEL,\n",
    "                \"messages\": messages,\n",
    "                \"temperature\": 0.0,  # Lower temperature for more deterministic responses\n",
    "                \"response_format\": {\n",
    "                    \"type\": \"json_schema\",\n",
    "                    \"json_schema\": {\n",
    "                        \"name\": \"security_response\",\n",
    "                        \"strict\": \"true\",\n",
    "                        \"schema\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"answer\": {\"type\": \"string\"}\n",
    "                            },\n",
    "                            \"required\": [\"answer\"]\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"max_tokens\": 500\n",
    "            },\n",
    "            timeout=300\n",
    "        )\n",
    "        \n",
    "        # Handle response\n",
    "        response.raise_for_status()\n",
    "        response_data = response.json()\n",
    "        \n",
    "        if not response_data.get(\"choices\"):\n",
    "            raise ValueError(\"Empty choices in API response\")\n",
    "            \n",
    "        try:\n",
    "            content = json.loads(response_data[\"choices\"][0][\"message\"][\"content\"])\n",
    "            if \"couldn't find context\" in content[\"answer\"].lower():\n",
    "                print(\"Response: Couldn't find relevant information in documents\")\n",
    "            else:\n",
    "                print(\"Response:\", content[\"answer\"])\n",
    "        except KeyError:\n",
    "            print(\"Invalid response format - missing 'answer' field\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Received invalid JSON:\", response_data[\"choices\"][0][\"message\"][\"content\"])\n",
    "\n",
    "except requests.exceptions.HTTPError as e:\n",
    "    error_message = f\"HTTP Error {e.response.status_code}: \"\n",
    "    try:\n",
    "        error_details = e.response.json()\n",
    "        error_message += error_details.get(\"error\", \"Unknown error\")\n",
    "    except json.JSONDecodeError:\n",
    "        error_message += e.response.text\n",
    "    print(error_message)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
